name: Code Quality

on:
  pull_request:
    branches: [main]
  push:
    branches: [main]

permissions:
  contents: read
  pull-requests: write

jobs:
  quality:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up uv
        uses: astral-sh/setup-uv@v4

      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/uv
          key: ${{ runner.os }}-uv-${{ hashFiles('**/uv.lock') }}

      - name: Install dependencies
        run: uv sync

      - name: Initialize feedback
        id: init
        run: |
          echo "" > /tmp/quality_feedback.md
          echo "## ğŸ” Code Quality Check Results" >> /tmp/quality_feedback.md
          echo "" >> /tmp/quality_feedback.md

      - name: Run Ruff linter
        id: ruff
        continue-on-error: true
        run: |
          echo "ğŸ” Running Ruff linter..."

          feedback="### ğŸ” Ruff Linting\n\n"

          if uv run ruff check . --output-format=concise > /tmp/ruff_output.txt 2>&1; then
            echo "âœ… Ruff linting passed!"
            feedback+="âœ… **Status:** PASSED - No linting errors\n"
            ruff_passed=true
          else
            echo "âŒ Ruff linting failed"
            cat /tmp/ruff_output.txt
            error_count=$(grep -c "error\|warning" /tmp/ruff_output.txt || echo "0")
            feedback+="âŒ **Status:** FAILED - Found $error_count issues\n\n"
            feedback+="\`\`\`\n"
            head -20 /tmp/ruff_output.txt >> /tmp/ruff_errors.txt
            feedback+="$(cat /tmp/ruff_errors.txt)\n"
            feedback+="\`\`\`\n\n"
            feedback+="ğŸ’¡ **Fix:** Run \`uv run ruff check --fix .\` to auto-fix most issues\n"
            ruff_passed=false
          fi

          echo -e "$feedback" >> /tmp/quality_feedback.md
          echo "" >> /tmp/quality_feedback.md
          echo "passed=$ruff_passed" >> $GITHUB_OUTPUT

      - name: Check formatting
        id: format
        continue-on-error: true
        run: |
          echo "ğŸ” Checking code formatting..."

          feedback="### ğŸ“ Code Formatting\n\n"

          if uv run ruff format --check . > /tmp/format_output.txt 2>&1; then
            echo "âœ… Code formatting is correct!"
            feedback+="âœ… **Status:** PASSED - All files properly formatted\n"
            format_passed=true
          else
            echo "âŒ Code formatting check failed"
            cat /tmp/format_output.txt
            file_count=$(grep -c "Would reformat:" /tmp/format_output.txt || echo "0")
            feedback+="âŒ **Status:** FAILED - $file_count files need formatting\n\n"
            feedback+="\`\`\`\n"
            cat /tmp/format_output.txt >> /tmp/quality_feedback.md
            feedback+="\`\`\`\n\n"
            feedback+="ğŸ’¡ **Fix:** Run \`uv run ruff format .\` to format all files\n"
            format_passed=false
          fi

          echo -e "$feedback" >> /tmp/quality_feedback.md
          echo "" >> /tmp/quality_feedback.md
          echo "passed=$format_passed" >> $GITHUB_OUTPUT

      - name: Run Pyright (excluding visualization.py)
        id: pyright
        continue-on-error: true
        run: |
          echo "ğŸ” Running Pyright type checker..."

          feedback="### ğŸ”¬ Type Checking\n\n"
          feedback+="â„¹ï¸ *Note: visualization.py is excluded due to Dash decorator type issues (configured in pyproject.toml)*\n\n"

          # Run pyright (visualization.py excluded via pyproject.toml)
          if uv run pyright > /tmp/pyright_output.txt 2>&1; then
            echo "âœ… Type checking passed!"
            feedback+="âœ… **Status:** PASSED - No type errors\n"
            pyright_passed=true
          else
            echo "âŒ Type checking failed"
            cat /tmp/pyright_output.txt
            error_line=$(grep "error" /tmp/pyright_output.txt | tail -1 || echo "")
            error_count=$(echo "$error_line" | grep -oP '\d+(?= error)' || echo "0")
            feedback+="âŒ **Status:** FAILED - Found $error_count type errors\n\n"
            feedback+="\`\`\`\n"
            tail -30 /tmp/pyright_output.txt >> /tmp/quality_feedback.md
            feedback+="\`\`\`\n\n"
            feedback+="ğŸ’¡ **Fix:** Add proper type hints and ensure all imports are correct\n"
            pyright_passed=false
          fi

          echo -e "$feedback" >> /tmp/quality_feedback.md
          echo "" >> /tmp/quality_feedback.md
          echo "passed=$pyright_passed" >> $GITHUB_OUTPUT

      - name: Run tests with coverage
        id: coverage
        continue-on-error: true
        run: |
          echo "ğŸ” Running tests with coverage..."

          feedback="### ğŸ“Š Test Coverage\n\n"
          feedback+="â„¹ï¸ *Target: 90%+ coverage on your NEW code (database, upload, validation)*\n"
          feedback+="â„¹ï¸ *Note: Dash callbacks in visualization.py may show lower coverage - this is expected*\n\n"

          if uv run pytest --cov=src --cov-report=term-missing --cov-report=json > /tmp/coverage_output.txt 2>&1; then
            echo "âœ… Tests passed!"
            tests_passed=true
          else
            echo "âŒ Tests failed"
            tests_passed=false
          fi

          cat /tmp/coverage_output.txt

          # Extract coverage percentage
          if [ -f coverage.json ]; then
            coverage_pct=$(python3 -c "import json; data=json.load(open('coverage.json')); print(int(data.get('totals', {}).get('percent_covered', 0)))")
          else
            coverage_pct=0
          fi

          echo "Coverage: $coverage_pct%"

          if [ $coverage_pct -ge 90 ]; then
            feedback+="âœ… **Status:** PASSED - ${coverage_pct}% coverage (â‰¥90%)\n"
            coverage_passed=true
          else
            feedback+="âŒ **Status:** FAILED - ${coverage_pct}% coverage (target: â‰¥90%)\n"
            feedback+="ğŸ“ **Focus on:** Ensure 90%+ coverage for YOUR new code:\n"
            feedback+="   - Database operations (CRUD functions)\n"
            feedback+="   - Pydantic model validation\n"
            feedback+="   - Upload file processing logic\n"
            feedback+="   - Any helper functions you create\n\n"
            coverage_passed=false
          fi

          feedback+="\nğŸ’¡ **Debug:** Run \`uv run pytest --cov=src --cov-report=html\` locally\n"
          feedback+="   Then open \`htmlcov/index.html\` to see exactly what's missing\n"

          echo -e "$feedback" >> /tmp/quality_feedback.md
          echo "" >> /tmp/quality_feedback.md
          echo "passed=$coverage_passed" >> $GITHUB_OUTPUT
          echo "coverage_pct=$coverage_pct" >> $GITHUB_OUTPUT

      - name: Calculate summary
        id: summary
        if: always()
        run: |
          # Count how many checks passed
          checks_passed=0
          checks_total=4

          ruff_passed="${{ steps.ruff.outputs.passed }}"
          format_passed="${{ steps.format.outputs.passed }}"
          pyright_passed="${{ steps.pyright.outputs.passed }}"
          coverage_passed="${{ steps.coverage.outputs.passed }}"

          [ "$ruff_passed" = "true" ] && checks_passed=$((checks_passed + 1))
          [ "$format_passed" = "true" ] && checks_passed=$((checks_passed + 1))
          [ "$pyright_passed" = "true" ] && checks_passed=$((checks_passed + 1))
          [ "$coverage_passed" = "true" ] && checks_passed=$((checks_passed + 1))

          percentage=$((checks_passed * 100 / checks_total))

          echo "---" >> /tmp/quality_feedback.md
          echo "" >> /tmp/quality_feedback.md
          echo "### ğŸ¯ Summary: $checks_passed / $checks_total checks passed ($percentage%)" >> /tmp/quality_feedback.md
          echo "" >> /tmp/quality_feedback.md

          if [ $percentage -eq 100 ]; then
            echo "âœ… **All quality checks passed!** âœ…" >> /tmp/quality_feedback.md
            all_passed=true
          else
            echo "âš ï¸ **Some quality checks failed.** Please fix the issues above." >> /tmp/quality_feedback.md
            echo "" >> /tmp/quality_feedback.md
            echo "### Quick Fix Commands:" >> /tmp/quality_feedback.md
            echo "\`\`\`bash" >> /tmp/quality_feedback.md
            echo "# Fix linting and formatting" >> /tmp/quality_feedback.md
            echo "uv run ruff check --fix ." >> /tmp/quality_feedback.md
            echo "uv run ruff format ." >> /tmp/quality_feedback.md
            echo "" >> /tmp/quality_feedback.md
            echo "# Check types" >> /tmp/quality_feedback.md
            echo "uv run pyright" >> /tmp/quality_feedback.md
            echo "" >> /tmp/quality_feedback.md
            echo "# Run tests with coverage" >> /tmp/quality_feedback.md
            echo "uv run pytest --cov=src --cov-report=html" >> /tmp/quality_feedback.md
            echo "\`\`\`" >> /tmp/quality_feedback.md
            all_passed=false
          fi

          echo "" >> /tmp/quality_feedback.md
          echo "---" >> /tmp/quality_feedback.md
          echo "" >> /tmp/quality_feedback.md
          echo "*This check validates code quality standards. Fix all issues before merging.*" >> /tmp/quality_feedback.md

          echo "checks_passed=$checks_passed" >> $GITHUB_OUTPUT
          echo "checks_total=$checks_total" >> $GITHUB_OUTPUT
          echo "percentage=$percentage" >> $GITHUB_OUTPUT
          echo "all_passed=$all_passed" >> $GITHUB_OUTPUT

      - name: Post PR comment
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const feedback = fs.readFileSync('/tmp/quality_feedback.md', 'utf8');

            const comments = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const botComment = comments.data.find(comment =>
              comment.user.type === 'Bot' &&
              comment.body.includes('ğŸ” Code Quality Check Results')
            );

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: feedback
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: feedback
              });
            }

      - name: Summary
        if: always()
        run: |
          echo ""
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ‰ Code Quality Check Complete!"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo ""
          echo "Checks: ${{ steps.summary.outputs.checks_passed }} / ${{ steps.summary.outputs.checks_total }} passed (${{ steps.summary.outputs.percentage }}%)"
          echo ""
          cat /tmp/quality_feedback.md

      - name: Fail if quality checks failed
        if: steps.summary.outputs.all_passed != 'true'
        run: |
          echo ""
          echo "âŒ Quality checks must pass before merging!"
          echo "   Please fix the issues and push again."
          exit 1
