# StraÃŸenprofil-Datenbank & Upload-System

> **[DE] Deutsche Version:** Sie lesen sie gerade!
> **[EN] English Version:** For full instructions in English, see [README.md](README.md)

Willkommen zur Ãœbung "StraÃŸenprofil-Datenbank & Upload-System"! Dies ist eine **Gruppenaufgabe**, bei der Sie eine bestehende Dash-Anwendung um Datenbank-Persistenz, Multi-Profil-Auswahl und Datei-Upload-Funktionen erweitern werden.

> **Hinweis:** Fehlermeldungen von automatisierten PrÃ¼fungen (GitHub Actions Workflows) erscheinen in **Englisch und Deutsch**.

## ðŸ“š Lernziele

Diese Ãœbung fÃ¼hrt Sie in **professionelle Feature-Entwicklungs-Workflows** ein und nutzt moderne Software-Engineering-Praktiken. Sie erleben Ihren ersten vollstÃ¤ndigen Entwicklungszyklus - eine pÃ¤dagogische Vorschau auf Agile/Scrum-Methodologien, die in spÃ¤teren Vorlesungen behandelt werden.

Durch diese Ãœbung werden Sie:

1. **Professionelle Feature-Entwicklung erleben** mit ordentlichen Planungs-, Implementierungs-, Test- und Review-Zyklen
2. **Datenbanken integrieren** in Web-Anwendungen (SQLite mit FastAPI/SQLModel ODER TinyDB)
3. **REST APIs entwerfen und implementieren** (bei FastAPI-Ansatz)
4. **Multi-Page Dash-Anwendungen erstellen** mit Datei-Upload und Datenvalidierung
5. **Pydantic-Validierung anwenden** fÃ¼r DatenintegritÃ¤t
6. **Kollaborative Entwicklung praktizieren** mit Feature Branches und Code Reviews
7. **Hohe Testabdeckung erreichen** (90%+ bei neuen Features) mit qualitÃ¤tsgetriebener Entwicklung
8. **Implementierungsentscheidungen dokumentieren** und technische Planung

## ðŸŽ¯ AufgabenÃ¼bersicht

Sie werden die bestehende StraÃŸenprofil-Viewer-Anwendung um folgende Features erweitern:

**Aktueller Stand:**
- Einzelnes Standard-StraÃŸenprofil (fest codiert)
- Kameraposition und Sichtstrahl-Visualisierung
- Schnittpunkt-Berechnung und Anzeige

**Ihre Aufgabe - HinzufÃ¼gen:**
1. **Dropdown-Auswahl** zur Auswahl aus mehreren gespeicherten StraÃŸenprofilen
2. **Datenbank-Backend** zur Persistierung von StraÃŸenprofilen
3. **Upload-Seite**, auf der Benutzer neue Profile via JSON-Dateien hinzufÃ¼gen kÃ¶nnen
4. **Profil-Vorschau** mit Grafik vor dem Speichern
5. **Profil-Umbenennung** auf der Upload-Seite
6. **Datenvalidierung** mit Pydantic-Modellen (validiert hochgeladene JSON-Dateien, z.B. Ablehnung wenn x/y-Koordinatenlisten unterschiedliche LÃ¤ngen haben)

## ðŸ—ï¸ Technische AnsÃ¤tze

Sie kÃ¶nnen zwischen zwei ImplementierungsansÃ¤tzen mit unterschiedlichen Punktwerten wÃ¤hlen:

### Ansatz 1: FastAPI + SQLModel + SQLite (5 Punkte mÃ¶glich)

**Architektur:**
- **Backend**: FastAPI REST API mit Endpunkten fÃ¼r CRUD-Operationen
- **Datenbank**: SQLite mit SQLModel ORM
- **Frontend**: Dash-App, die die API konsumiert
- **Migration**: Datenbank-Initialisierung und Seeding-Skripte

**Warum dieser Ansatz:**
- Industriestandard-Architektur (Separation of Concerns)
- Skalierbar und testbar
- Anspruchsvoller, ermÃ¶glicht volle 5 Punkte

**Hauptkomponenten:**
```
src/road_profile_viewer/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py          # FastAPI App
â”‚   â””â”€â”€ routes.py        # API Endpunkte
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models.py        # SQLModel Datenbankmodelle
â”‚   â””â”€â”€ connection.py    # Datenbank-Setup
â”œâ”€â”€ models.py            # Pydantic Validierungsmodelle
â””â”€â”€ visualization.py     # Aktualisierte Dash-App mit API-Aufrufen
```

### Ansatz 2: TinyDB (4 Punkte mÃ¶glich)

**Architektur:**
- **Datenbank**: TinyDB (JSON-basiert, kein separates Backend nÃ¶tig)
- **Frontend**: Dash-App mit direktem TinyDB-Zugriff
- **Einfacher**: Aller Code in Dash-Anwendung integriert

**Warum dieser Ansatz:**
- Leichtgewichtig und einfach
- Keine API-Schicht nÃ¶tig
- Gut zum Lernen von Datenbank-Grundlagen

**Hauptkomponenten:**
```
src/road_profile_viewer/
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ db.py            # TinyDB Operationen
â”œâ”€â”€ models.py            # Pydantic Validierungsmodelle
â””â”€â”€ visualization.py     # Aktualisierte Dash-App mit TinyDB
```

**WÃ¤hlen Sie basierend auf:**
- ZeitverfÃ¼gbarkeit Ihres Teams
- Lernziele (FastAPI lernen wollen?)
- Ambitionsniveau (Ziel: volle 5 Punkte?)

## ðŸ“‹ Anforderungen

### 1. Implementierung (1,5 Punkte)

#### Dropdown-Auswahl (0,6 Punkte)
- [ ] Dropdown-Komponente auf Hauptseite zur Auswahl von StraÃŸenprofilen
- [ ] Dropdown listet alle verfÃ¼gbaren Profile nach Namen auf
- [ ] Auswahl eines Profils aktualisiert die Visualisierung
- [ ] Standard-Profil beim App-Start vorausgewÃ¤hlt

#### Upload-Seite (0,9 Punkte)
- [ ] Neue Seite/Route in Dash-App erstellen (`/upload`)
- [ ] Datei-Upload-Komponente, die JSON-Dateien akzeptiert
- [ ] Vorschau-Grafik, die hochgeladenes Profil vor dem Speichern zeigt
- [ ] Texteingabe zum Umbenennen des Profils
- [ ] BestÃ¤tigungs-Button zum Speichern in Datenbank
- [ ] Erfolgs-/Fehlermeldungen nach Upload
- [ ] Navigation zwischen Hauptseite und Upload-Seite

### 2. Backend & Datenbank (1,0 Punkte)

#### Datenbank-Schema (0,3 Punkte)
- [ ] StraÃŸenprofil-Modell mit Feldern: `id`, `name`, `x_coordinates`, `y_coordinates`
- [ ] Unique-Constraint auf Profilnamen
- [ ] Richtige Datentypen (list/array fÃ¼r Koordinaten)

#### Datenbank-Operationen (0,4 Punkte)
- [ ] Create (neues Profil einfÃ¼gen)
- [ ] Read (alle Profile abrufen, nach Name/ID abrufen)
- [ ] Update (optional, aber empfohlen)
- [ ] Delete (optional, aber empfohlen)

#### Migration/Seed (0,3 Punkte)
- [ ] Skript zur Datenbank-Initialisierung
- [ ] Standard-Profil beim ersten Start einfÃ¼gen
- [ ] Datenbank-Datei in `.gitignore` (nicht committen)

**FastAPI-Ansatz Bonus (+1 Punkt):**
- [ ] REST API Endpunkte: `GET /profiles`, `POST /profiles`, `GET /profiles/{id}`
- [ ] Ordentliches Error Handling (404, 409 Konflikt, 422 Validierung)
- [ ] FastAPI automatische Dokumentation (`/docs`)
- [ ] Separation of Concerns (API-Schicht getrennt von Dash)

### 3. Datenvalidierung (in Implementierungspunkten enthalten)

- [ ] Pydantic-Modell passend zum Beispiel-JSON-Schema
- [ ] Validierungsregeln:
  - Name: 1-100 Zeichen, nicht leer
  - `x_coordinates` und `y_coordinates`: gleiche LÃ¤nge, mindestens 2 Punkte
  - Koordinaten mÃ¼ssen numerisch sein (Floats)
- [ ] Klare Fehlermeldungen bei Validierungsfehlern
- [ ] Beispiel-JSON-Datei bereitgestellt in `docs/example-road-profile.json`

### 4. Testing (0,5 Punkte)

- [ ] **90%+ C1-Abdeckung** fÃ¼r alle neuen Features
- [ ] Unit Tests fÃ¼r:
  - Datenbank-Operationen (CRUD)
  - API-Endpunkte (bei FastAPI-Ansatz)
  - Pydantic-Validierung (gÃ¼ltige und ungÃ¼ltige FÃ¤lle)
  - Upload-FunktionalitÃ¤t
  - Dropdown-Auswahl-Logik
- [ ] Integrationstests fÃ¼r Upload-Workflow
- [ ] Coverage-Report generiert durch pytest-cov

### 5. Git Workflow & Zusammenarbeit (0,5 Punkte)

- [ ] **Mindestens 2 Feature Branches** mit beschreibenden Namen (z.B. `feature/database-setup`, `feature/upload-page`)
- [ ] **Mehrere Mitwirkende**: Jeder Branch hat Commits von mindestens einem Teammitglied
- [ ] **Inkrementelle Commits** mit beschreibenden Nachrichten (>20 Zeichen)
- [ ] **Implementierungsplan** dokumentiert in `docs/implementation-plan.md`
- [ ] **LLM-Prompts** (falls verwendet) gespeichert im `docs/llm-prompts/` Ordner

### 6. Code Review (0,5 Punkte)

- [ ] Alle Features via **Pull Requests** implementiert
- [ ] PRs verwenden das bereitgestellte **PR-Beschreibungstemplate**
- [ ] Jeder PR von mindestens **einem anderen Teammitglied** reviewt
- [ ] Reviews enthalten substantielles Feedback (nicht nur "LGTM")
- [ ] Alle CI-Checks bestanden vor Merge

## ðŸ‘¥ Gruppenarbeit

### Team-Setup
- **GruppengrÃ¶ÃŸe**: 2-4 Studenten
- **Bildung**: Selbstorganisiert oder durch Dozent zugewiesen
- **Repository**: Ein Repository pro Gruppe via GitHub Classroom

### Kollaborations-Anforderungen

1. **Implementierungsplan** (`docs/implementation-plan.md`):
   ```markdown
   # Implementierungsplan

   ## Teammitglieder
   - [Name] - [Rolle/Verantwortlichkeiten]
   - [Name] - [Rolle/Verantwortlichkeiten]

   ## Technische Entscheidung
   - [ ] FastAPI + SQLModel + SQLite (5 Punkte)
   - [ ] TinyDB (4 Punkte)

   ## Feature-Aufteilung
   | Feature | Branch | Verantwortlich | Status |
   |---------|--------|----------------|--------|
   | Datenbank-Setup | feature/database | [Name] | âœ… |
   | Upload-Seite | feature/upload | [Name] | ðŸ”„ |

   ## Test-Strategie
   [Wie Sie 90% Abdeckung erreichen]
   ```

2. **Branch-Strategie**:
   - Minimum 2 Feature Branches (Empfehlung: 3-4)
   - Vorgeschlagene Branches:
     - `feature/database-setup` - Datenbank-Schema, Modelle, Seed-Skript
     - `feature/dropdown-selector` - Hauptseiten-Dropdown-Integration
     - `feature/upload-page` - Neue Upload-Seite mit Vorschau
     - `feature/api-endpoints` - FastAPI-Routen (falls zutreffend)

3. **Arbeitsverteilung**:
   - Jedes Teammitglied arbeitet an mindestens einem Feature Branch
   - GitHub Issues zur Aufgabenverfolgung verwenden
   - TÃ¤gliche Standups (in Issue-Kommentaren dokumentieren)

4. **LLM-Nutzung** (Optional aber empfohlen):
   - Falls Sie ChatGPT, Claude oder andere LLMs nutzen, Prompts speichern
   - Ordner erstellen: `docs/llm-prompts/`
   - Dateinamen: `JJJJ-MM-TT-feature-name.md`
   - Sowohl Prompts als auch relevante Antworten einbeziehen

## ðŸš€ Erste Schritte

> **Wichtig:** Sie sind **vollkommen unabhÃ¤ngig** in Ihrer Herangehensweise an diese Aufgabe. Die folgenden Schritte sind **VorschlÃ¤ge** zur Orientierung, aber Sie kÃ¶nnen gerne Ihren eigenen Workflow entwickeln, der am besten fÃ¼r Ihr Team funktioniert!

### Schritt 1: Aufgabe annehmen & Team bilden

```bash
# Jedes Teammitglied nimmt die GitHub Classroom Aufgabe an
# Erstes Mitglied erstellt ein neues Team
# Andere Mitglieder treten dem bestehenden Team bei

# Team-Repository klonen
git clone https://github.com/hs-aalen-software-engineering/road-profile-db-TEAM-NAME.git
cd road-profile-db-TEAM-NAME
```

### Schritt 2: Aktuelle Anwendung verstehen

```bash
# AbhÃ¤ngigkeiten installieren
uv sync

# Aktuelle App ausfÃ¼hren, um zu sehen, was sie tut
uv run python -m road_profile_viewer

# Browser Ã¶ffnen: http://127.0.0.1:8050/
# Mit Winkel-Eingabe spielen, um Strahlenschnitt zu sehen
```

**Code erkunden:**
- `src/road_profile_viewer/main.py` - Einstiegspunkt
- `src/road_profile_viewer/visualization.py` - Dash UI
- `src/road_profile_viewer/geometry.py` - Schnittberechnungen
- `src/road_profile_viewer/road.py` - Aktuelle Profil-Generierung

### Schritt 3: Implementierung planen

**Halten Sie ein Team-Meeting ab, um zu entscheiden:**

1. Welcher technische Ansatz? (FastAPI oder TinyDB)
2. Wie teilen Sie die Arbeit auf? (wer macht was)
3. Wie wird Ihre Branch-Strategie aussehen?
4. Wie werden Sie 90% Testabdeckung erreichen?

**FÃ¼llen Sie das bereitgestellte Template aus:** `docs/implementation-plan.md`

Das Template ist bereits in Ihrem Repository - passen Sie es an die BedÃ¼rfnisse Ihres Teams an.

### Schritt 4: Entwicklungsumgebung einrichten

**Starter-Dateien erstellen:**

```bash
# 1. Pydantic-Modelle
# src/road_profile_viewer/models.py enthÃ¤lt einen STARTER-VORSCHLAG
# Sie sind komplett frei, Ihre eigenen Modelle zu entwerfen!
# Denken Sie daran: Verschieben Sie diese Datei entsprechend Ihrer gewÃ¤hlten Architektur
# (Auf Root-Ebene behalten ODER in database/ oder api/ Ordner verschieben)

# 2. Beispiel-JSON-Format Ã¼berprÃ¼fen
cat docs/example-road-profile.json
```

**Beispiel-JSON-Format** (`docs/example-road-profile.json`):
```json
{
  "name": "bergstrasse",
  "x_coordinates": [0.0, 10.0, 20.0, 30.0, 40.0, 50.0],
  "y_coordinates": [0.0, 2.0, 5.0, 8.0, 6.0, 4.0]
}
```

### Schritt 5: Features entwickeln

**Teilen Sie die Arbeit unter den Teammitgliedern auf.** Erstellen Sie Feature Branches fÃ¼r jede Hauptkomponente. Hier sind einige vorgeschlagene Arbeitspakete, aber Sie kÃ¶nnen auch anders organisieren:

- Datenbank-Setup und Schema
- Dropdown-Selector-Integration
- Upload-Seite mit Validierung
- API-Endpunkte (falls FastAPI verwendet wird)
- Testing und Coverage

**Beispiel-Workflow fÃ¼r ein Feature:**

```bash
# Erstellen Sie Ihren Feature Branch
git checkout -b feature/ihr-feature-name

# Implementieren Sie Ihr Feature
# Schreiben Sie Tests wÃ¤hrend der Entwicklung
# Committen Sie inkrementell mit aussagekrÃ¤ftigen Nachrichten

# Pushen und PR mit dem Template erstellen
git push -u origin feature/ihr-feature-name
gh pr create
```

**Denken Sie daran:** Jedes Feature sollte Tests haben, Code-QualitÃ¤tsstandards folgen und durch Code Review gehen, bevor es gemergt wird.

### Schritt 6: Code Review-Prozess

**FÃ¼r jeden PR:**

1. **Autor**: Sicherstellen, dass CI-Checks bestehen vor Review-Anfrage
2. **Reviewer**: PR prÃ¼fen anhand Template-Checkliste
3. **Reviewer**: Lokal testen:
   ```bash
   git fetch origin
   git checkout feature/database-setup
   uv sync
   uv run pytest --cov=src --cov-report=term-missing
   uv run python -m road_profile_viewer
   ```
4. **Reviewer**: Kommentare hinterlassen, Ã„nderungen anfordern oder genehmigen
5. **Autor**: Feedback adressieren, Updates pushen
6. **Merge**: Nur nach Genehmigung + alle CI-Checks bestanden

### Schritt 7: Integration & Testing

```bash
# Nach Merge aller Features, End-to-End verifizieren:

# 1. Frische Installation
uv sync

# 2. Abdeckung fÃ¼r allen neuen Code prÃ¼fen
uv run pytest --cov=src --cov-report=html --cov-report=term
# htmlcov/index.html Ã¶ffnen fÃ¼r detaillierte Abdeckung

# 3. Manuelle Test-Checkliste:
# - [ ] App startet ohne Fehler
# - [ ] Dropdown zeigt Standard-Profil
# - [ ] Verschiedene Profile aus Dropdown auswÃ¤hlbar
# - [ ] Upload-Seite erreichbar
# - [ ] GÃ¼ltige JSON-Datei hochladbar
# - [ ] Vorschau-Grafik erscheint korrekt
# - [ ] Profil vor Speichern umbenennbar
# - [ ] Profil erscheint im Dropdown nach Upload
# - [ ] UngÃ¼ltiges JSON zeigt Fehlermeldung
# - [ ] Datenbank persistiert nach App-Neustart

# 4. Code-QualitÃ¤tsprÃ¼fungen
uv run ruff check .
uv run ruff format --check .
uv run pyright
```

## ðŸ” Bewertungsrubrik

| Kategorie | Punkte | Kriterien |
|-----------|--------|-----------|
| **Implementierung** | 1,5 | Dropdown (0,6) + Upload-Seite mit Vorschau/Umbenennung (0,9) |
| **Backend/Datenbank** | 1,0 | Schema (0,3) + CRUD-Operationen (0,4) + Seed-Skript (0,3) |
| **Testing** | 0,5 | 90%+ C1-Abdeckung fÃ¼r neue Features |
| **Git Workflow** | 0,5 | â‰¥2 Branches, klare Commits, Implementierungsplan |
| **Code Review** | 0,5 | PRs mit Template, Peer Reviews, CI bestanden |
| **BONUS: FastAPI** | +1,0 | REST API + ordentliches Error Handling + Separation of Concerns |
| **Gesamt (TinyDB)** | **4,0** | Maximal erreichbar mit TinyDB-Ansatz |
| **Gesamt (FastAPI)** | **5,0** | Begrenzt auf 5,0 (Bonus erlaubt Fehlertoleranz bis 6,0) |

### Automatisierte PrÃ¼fungen

GitHub Actions verifiziert automatisch:

- âœ… **Code-QualitÃ¤t**: Ruff Linting, Pyright Type Checking
- âœ… **Test-Abdeckung**: pytest-cov mit 90% Schwellenwert fÃ¼r neuen Code
- âœ… **Git Workflow**: â‰¥2 Feature Branches, mehrere Autoren, Commit-QualitÃ¤t
- âœ… **PR Reviews**: Alle PRs genehmigt vor Merge
- âœ… **Struktur**: Erforderliche Dateien existieren (database/, models.py, etc.)

> **âš ï¸ Wichtiger Hinweis zu automatisierten PrÃ¼fungen:**
>
> Die GitHub Actions Workflows dienen **nur zur Orientierung** und geben hilfreiche RÃ¼ckmeldungen wÃ¤hrend der Entwicklung. Jedoch:
>
> - **Die finale Bewertung erfolgt ausschlieÃŸlich durch den Dozenten**, nicht durch automatisierte Checks
> - Die Checks sind bewusst offen formuliert und decken mÃ¶glicherweise nicht alle gÃ¼ltigen LÃ¶sungsansÃ¤tze ab
> - **Blockieren Sie sich nicht**, wenn ein Check fehlschlÃ¤gt, Sie aber eine gÃ¼ltige alternative LÃ¶sung haben - dokumentieren Sie Ihren Ansatz im Implementierungsplan
> - Wenn automatisierte Checks nicht zu Ihren Designentscheidungen passen, ist das in Ordnung! Der Dozent bewertet auf Basis von Korrektheit, nicht Check-KonformitÃ¤t
> - Fokussieren Sie sich darauf, eine funktionierende, gut getestete Anwendung zu bauen, anstatt jede automatisierte Regel zu erfÃ¼llen

### Manuelle Bewertung

Dozent wird:
- Ihr Repository klonen
- `uv sync` und `uv run python -m road_profile_viewer` ausfÃ¼hren
- Alle Features testen (Dropdown, Upload, Vorschau, Persistenz)
- QualitÃ¤t des Implementierungsplans Ã¼berprÃ¼fen
- Code-Architektur-Entscheidungen prÃ¼fen
- Test-Strategie verifizieren

## ðŸ“„ Erforderliche Dateien Checkliste

**Dokumentation:**
- [ ] `docs/implementation-plan.md` - Plan Ihres Teams
- [ ] `docs/example-road-profile.json` - Bereitgestelltes Beispiel (enthalten)
- [ ] `docs/llm-prompts/` - LLM-Prompts (falls verwendet)

**Code (variiert je nach Ansatz):**

**Beide AnsÃ¤tze:**
- [ ] `src/road_profile_viewer/models.py` - Pydantic Validierungsmodelle
- [ ] Aktualisierte `src/road_profile_viewer/visualization.py` - Dropdown + Upload-Seite

**FastAPI-Ansatz:**
- [ ] `src/road_profile_viewer/api/main.py` - FastAPI App
- [ ] `src/road_profile_viewer/api/routes.py` - API Endpunkte
- [ ] `src/road_profile_viewer/database/models.py` - SQLModel Modelle
- [ ] `src/road_profile_viewer/database/connection.py` - DB Setup

**TinyDB-Ansatz:**
- [ ] `src/road_profile_viewer/database/db.py` - TinyDB Operationen

**Tests:**
- [ ] `tests/test_models.py` - Pydantic Validierungstests
- [ ] `tests/test_database.py` - Datenbank-Operations-Tests
- [ ] `tests/test_upload.py` - Upload-FunktionalitÃ¤ts-Tests
- [ ] `tests/test_api.py` - API Endpunkt-Tests (nur FastAPI)

## ðŸ“š Technische Ressourcen

### FastAPI + SQLModel Ansatz
- [FastAPI Dokumentation](https://fastapi.tiangolo.com/)
- [SQLModel Dokumentation](https://sqlmodel.tiangolo.com/)
- [Pydantic Validierung](https://docs.pydantic.dev/latest/)

### TinyDB Ansatz
- [TinyDB Dokumentation](https://tinydb.readthedocs.io/)
- [TinyDB Tutorial](https://tinydb.readthedocs.io/en/latest/getting-started.html)

### Dash Multi-Page Apps
- [Dash Pages](https://dash.plotly.com/urls)
- [Dash Upload Component](https://dash.plotly.com/dash-core-components/upload)

### Testing
- [pytest Dokumentation](https://docs.pytest.org/)
- [pytest-cov Coverage](https://pytest-cov.readthedocs.io/)

## ðŸŽ‰ Erfolgskriterien

Ihre Aufgabe ist abgeschlossen, wenn:

- âœ… Alle Features funktionieren wie persÃ¶nlich demonstriert
- âœ… Alle automatisierten CI-Checks bestanden
- âœ… Testabdeckung â‰¥90% fÃ¼r neuen Code
- âœ… Alle PRs reviewt und gemergt
- âœ… Implementierungsplan dokumentiert Ihre Entscheidungen
- âœ… Code-QualitÃ¤t erfÃ¼llt Standards (Ruff, Pyright)

**Herzlichen GlÃ¼ckwunsch zum Aufbau einer Full-Stack-Datenbankanwendung!**

---

**Aufgabe erstellt**: 2025-11-19
**Kurs**: Software Engineering - HS Aalen
**Dozent**: Dominik Mueller
